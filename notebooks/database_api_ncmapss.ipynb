{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indian-scanning",
   "metadata": {},
   "source": [
    "# Database API example for N-CMAPSS dataset\n",
    "\n",
    "### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfied-indiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\Dropbox\\NASA\\phm2021_data_challenge\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "print(base_dir)\n",
    "sys.path.insert(1, base_dir)\n",
    "from package.api import DB as api\n",
    "import package.utils as utils\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-screw",
   "metadata": {},
   "source": [
    "## DATA EXTRACTION\n",
    "### 1. load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "super-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-CMAPSS_DS01-005.h5\n",
      "dev\n",
      "<N-CMAPSS_DS01-005.h5> : [1. 2. 3. 4. 5. 6.]\n",
      "test\n",
      "<N-CMAPSS_DS01-005.h5> : [ 7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "h5_dir = 'data_h5'\n",
    "fnames = [\n",
    "    'N-CMAPSS_DS01-005.h5',\n",
    "    'N-CMAPSS_DS03-012.h5',\n",
    "    'N-CMAPSS_DS04.h5',\n",
    "    'N-CMAPSS_DS05.h5',\n",
    "    'N-CMAPSS_DS06.h5',\n",
    "    'N-CMAPSS_DS07.h5',\n",
    "    'N-CMAPSS_DS08a-009.h5',\n",
    "    'N-CMAPSS_DS08c-008.h5'\n",
    "]\n",
    "\n",
    "sets = ['dev', 'test']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "asset_id = 1\n",
    "\n",
    "for filename in fnames:\n",
    "    print(filename)\n",
    "    for _set in sets:\n",
    "        group_id = -1\n",
    "        if _set == 'dev':\n",
    "            group_id = 1\n",
    "        elif _set == 'test':\n",
    "            group_id = 2\n",
    "            \n",
    "        print(_set)\n",
    "        with h5py.File(os.path.join(base_dir, h5_dir, filename), 'r') as hdf:\n",
    "            a_data = np.array(hdf.get(f\"A_{_set}\"))\n",
    "            w_data = np.array(hdf.get(f\"W_{_set}\"))\n",
    "            x_data = np.array(hdf.get(f\"X_s_{_set}\"))\n",
    "            v_data = np.array(hdf.get(f\"X_v_{_set}\"))\n",
    "            t_data = np.array(hdf.get(f\"T_{_set}\"))\n",
    "            y_data = np.array(hdf.get(f\"Y_{_set}\"))\n",
    "\n",
    "            a_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('A_var')))]\n",
    "            w_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('W_var')))]\n",
    "            x_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('X_s_var')))]\n",
    "            v_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('X_v_var')))]\n",
    "            t_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('T_var')))]\n",
    "            \n",
    "        df_a = pd.DataFrame(data=a_data, columns=a_labels)\n",
    "        df_a['asset_id'] = -1\n",
    "        df_a['dataset'] = filename.split('_')[1].split('.')[0]\n",
    "        df_a['group_id'] = group_id\n",
    "        df_w = pd.DataFrame(data=w_data, columns=w_labels)\n",
    "        df_x = pd.DataFrame(data=x_data, columns=x_labels)\n",
    "        df_v = pd.DataFrame(data=v_data, columns=v_labels)\n",
    "        df_t = pd.DataFrame(data=t_data, columns=t_labels)\n",
    "        df_y = pd.DataFrame(data=y_data, columns=['y'])\n",
    "        print(f\"<{filename}> : {pd.unique(df_a.unit)}\")\n",
    "        for n in list(pd.unique(df_a.unit)):\n",
    "            df_a.loc[df_a['unit'] == n, 'asset_id'] = asset_id\n",
    "            asset_id = asset_id + 1\n",
    "\n",
    "        df_temp = pd.concat([df_a, df_y, df_w, df_x, df_v, df_t], axis=1)\n",
    "        #print(df_temp.head())\n",
    "        if(len(df)) == 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            df = pd.concat([df, df_temp], axis=0)      \n",
    "        \n",
    "        del df_a, df_w, df_x, df_v, df_t, df_y, a_data, w_data, t_data, x_data, y_data, df_temp\n",
    "    break\n",
    "    ####### NOTICE THE BREAK HERE!! only loading first dataset for testing purposes!!\n",
    "    \n",
    "df = df.round(5)\n",
    "df.asset_id = df.asset_id.astype(int)\n",
    "df.unit = df.unit.astype(int)\n",
    "df.cycle = df.cycle.astype(int)\n",
    "df.hs = df.hs.astype(int)\n",
    "df.Fc = df.Fc.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-capability",
   "metadata": {},
   "source": [
    "### 2. get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-basketball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod', 'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod', 'LPT_eff_mod', 'LPT_flow_mod']\n",
      "['alt', 'Mach', 'TRA', 'T2', 'T24', 'T30', 'T48', 'T50', 'P15', 'P2', 'P21', 'P24', 'Ps30', 'P40', 'P50', 'Nf', 'Nc', 'Wf']\n",
      "['T40', 'P30', 'P45', 'W21', 'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC', 'phi']\n"
     ]
    }
   ],
   "source": [
    "y_labels = t_labels\n",
    "t_labels = []\n",
    "t_labels.append(w_labels)\n",
    "t_labels.append(x_labels)\n",
    "t_labels = [l for labels in t_labels for l in labels]\n",
    "print(y_labels)\n",
    "print(t_labels)\n",
    "print(v_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-mention",
   "metadata": {},
   "source": [
    "### 3. create the augmented auxiliary data by aggregating over units\n",
    "#### NOTE the \"asset_id\" is used to assign unique numbers to the units across all datasets since the unit numbers restart in each dataset\n",
    "#### NOTE this value does not reflect the assets true ID stored in the database if there are already units in the database (but this impacts nothing, just fyi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suburban-penalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>Fc</th>\n",
       "      <th>unit</th>\n",
       "      <th>dataset</th>\n",
       "      <th>age</th>\n",
       "      <th>eol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  group_id  Fc  unit   dataset  age  eol\n",
       "0         1         1   1     1  DS01-005  0.0  100\n",
       "1         2         1   3     2  DS01-005  0.0   75\n",
       "2         3         1   2     3  DS01-005  0.0  100\n",
       "3         4         1   1     4  DS01-005  0.0   95\n",
       "4         5         1   3     5  DS01-005  0.0   89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = df[['asset_id', 'group_id', 'Fc', 'unit', 'dataset', 'cycle']].groupby('asset_id').agg({'group_id': 'max',\n",
    "                                                                                                 'Fc':'max',\n",
    "                                                                                                 'unit':'max',\n",
    "                                                                                                 'dataset':'max', \n",
    "                                                                                                 'cycle':['min','max']})\n",
    "df_aux.reset_index(inplace=True)\n",
    "df_aux.columns=['asset_id', 'group_id', 'Fc', 'unit', 'dataset', 'age', 'eol']\n",
    "df_aux.age = df_aux.age - 1.0\n",
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-render",
   "metadata": {},
   "source": [
    "### 4. connect to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "trying-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] connecting to db.\n",
      "[INFO] connected.\n"
     ]
    }
   ],
   "source": [
    "# THESE ARE YOUR CREDENTIALS IN PLAIN TEXT!\n",
    "params = utils.get_aws_secret(\"/secret/ncmapssdb\")\n",
    "#print(params)\n",
    "db, cur =  api.connect(params)\n",
    "db.set_session(autocommit=True)\n",
    "del(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-express",
   "metadata": {},
   "source": [
    "### 5. create asset type\n",
    "#### NOTE if the asset type already exists, the function simply returns it\n",
    "#### BIG NOTE the asset_type and subtype must combine to form the table name of the component, so the table would be engine_ncmapss_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bigger-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    type  subtype                                description\n",
      "0   1  engine  ncmapss  turbine engine from N-CMAPSS dataset unit\n"
     ]
    }
   ],
   "source": [
    "asset_type = api._create_asset_type(asset_type='engine', subtype='ncmapss', description='turbine engine from N-CMAPSS dataset unit', db=db, cur=cur)\n",
    "print(asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-adult",
   "metadata": {},
   "source": [
    "### 6. create assets and components\n",
    "#### make some serial numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleasant-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_numbers = [utils.generate_serial_number(length=8) for _ in range(len(df_aux))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-interface",
   "metadata": {},
   "source": [
    "#### this could be rewritten as a function for use with df_aux.apply()...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recent-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  type_id     owner process_id serial_number   common_name  age    eol  \\\n",
      "0   1        1  darrahts       None      ZHKAAqpj  ncmapss unit  0.0  100.0   \n",
      "\n",
      "     rul   units  \n",
      "0  100.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   2        1  darrahts       None      OuruGsTe  ncmapss unit  0.0  75.0   \n",
      "\n",
      "    rul   units  \n",
      "0  75.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age    eol  \\\n",
      "0   3        1  darrahts       None      dtSPsU5o  ncmapss unit  0.0  100.0   \n",
      "\n",
      "     rul   units  \n",
      "0  100.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   4        1  darrahts       None      BwpiGwPW  ncmapss unit  0.0  95.0   \n",
      "\n",
      "    rul   units  \n",
      "0  95.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   5        1  darrahts       None      V6PaIoTe  ncmapss unit  0.0  89.0   \n",
      "\n",
      "    rul   units  \n",
      "0  89.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   6        1  darrahts       None      eeOEjzXm  ncmapss unit  0.0  94.0   \n",
      "\n",
      "    rul   units  \n",
      "0  94.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   7        1  darrahts       None      RcW6smYb  ncmapss unit  0.0  90.0   \n",
      "\n",
      "    rul   units  \n",
      "0  90.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   8        1  darrahts       None      S9EBxhsS  ncmapss unit  0.0  89.0   \n",
      "\n",
      "    rul   units  \n",
      "0  89.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0   9        1  darrahts       None      qPOQr6I9  ncmapss unit  0.0  80.0   \n",
      "\n",
      "    rul   units  \n",
      "0  80.0  cycles  \n",
      "None\n",
      "   id  type_id     owner process_id serial_number   common_name  age   eol  \\\n",
      "0  10        1  darrahts       None      Bsn5VBJd  ncmapss unit  0.0  82.0   \n",
      "\n",
      "    rul   units  \n",
      "0  82.0  cycles  \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(df_aux)):\n",
    "    asset = api._create_asset(type_id=int(asset_type.id.values[0]),\n",
    "                              common_name='ncmapss unit',\n",
    "                              age=float(df_aux.iloc[i].age),\n",
    "                              eol=float(df_aux.iloc[i].eol),\n",
    "                              rul=float(df_aux.iloc[i].eol - df_aux.iloc[i].age),\n",
    "                              units='cycles',\n",
    "                              serial_number=serial_numbers[i],\n",
    "                              db=db,\n",
    "                              cur=cur)\n",
    "    print(asset)\n",
    "\n",
    "    component = api._create_component(asset=asset, \n",
    "                                      group_id=df_aux.iloc[i].group_id, \n",
    "                                      Fc=df_aux.iloc[i].Fc,\n",
    "                                      unit=df_aux.iloc[i].unit, \n",
    "                                      dataset=df_aux.iloc[i].dataset, \n",
    "                                      db=db, \n",
    "                                      cur=cur)\n",
    "    print(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-assembly",
   "metadata": {},
   "source": [
    "### 7. convert index to datetime (the timescaledb extention to postgres requires a \"time\" column)\n",
    "- given there is no time information with the provided data, set the interval at your discretion (ex: 1 second)\n",
    "#### grab last record from db, and start index from that value (assuming the current dataframe does not contain any records already in the database)\n",
    "#### the \"id\" column will only start at 1 once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hundred-bacteria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dt</th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>Fc</th>\n",
       "      <th>hs</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>group_id</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>fan_eff_mod</th>\n",
       "      <th>fan_flow_mod</th>\n",
       "      <th>LPC_eff_mod</th>\n",
       "      <th>LPC_flow_mod</th>\n",
       "      <th>HPC_eff_mod</th>\n",
       "      <th>HPC_flow_mod</th>\n",
       "      <th>HPT_eff_mod</th>\n",
       "      <th>HPT_flow_mod</th>\n",
       "      <th>LPT_eff_mod</th>\n",
       "      <th>LPT_flow_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1970-01-01 00:00:01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1970-01-01 00:00:02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1970-01-01 00:00:03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1970-01-01 00:00:04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   dt  unit  cycle  Fc  hs  asset_id   dataset  group_id  \\\n",
       "0   1  1970-01-01 00:00:00     1      1   1   1         1  DS01-005         1   \n",
       "1   2  1970-01-01 00:00:01     1      1   1   1         1  DS01-005         1   \n",
       "2   3  1970-01-01 00:00:02     1      1   1   1         1  DS01-005         1   \n",
       "3   4  1970-01-01 00:00:03     1      1   1   1         1  DS01-005         1   \n",
       "4   5  1970-01-01 00:00:04     1      1   1   1         1  DS01-005         1   \n",
       "\n",
       "    y  ...  fan_eff_mod  fan_flow_mod  LPC_eff_mod  LPC_flow_mod  HPC_eff_mod  \\\n",
       "0  99  ...          0.0           0.0          0.0           0.0          0.0   \n",
       "1  99  ...          0.0           0.0          0.0           0.0          0.0   \n",
       "2  99  ...          0.0           0.0          0.0           0.0          0.0   \n",
       "3  99  ...          0.0           0.0          0.0           0.0          0.0   \n",
       "4  99  ...          0.0           0.0          0.0           0.0          0.0   \n",
       "\n",
       "   HPC_flow_mod  HPT_eff_mod  HPT_flow_mod  LPT_eff_mod  LPT_flow_mod  \n",
       "0           0.0      -0.0006           0.0          0.0           0.0  \n",
       "1           0.0      -0.0006           0.0          0.0           0.0  \n",
       "2           0.0      -0.0006           0.0          0.0           0.0  \n",
       "3           0.0      -0.0006           0.0          0.0           0.0  \n",
       "4           0.0      -0.0006           0.0          0.0           0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_id = api.execute(\"select max(id) from summary_tb;\", db).values[0][0]\n",
    "if type(start_id) == type(None):\n",
    "    start_id = 0\n",
    "df.index = pd.to_datetime(df.index, unit='s', origin='unix')\n",
    "df.index.names=['dt']\n",
    "df.reset_index(inplace=True)\n",
    "df.index += start_id + 1\n",
    "df.index.names=['id']\n",
    "df.reset_index(inplace=True)\n",
    "df.loc[:, 'dt'] = df.loc[:, 'dt'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-colonial",
   "metadata": {},
   "source": [
    "- the data tables are broken down slightly different then they are presented in the dataset, see the table schema\n",
    "- summary_tb: id (auto generated), asset_id, cycle, alt, Mach, TRA, T2)\n",
    "- telemetry_tb: dt (timestamp or datetime), all of the telemetry columns\n",
    "- degradation_tb: dt (timestamp or datetime), all of the degradation columns and health state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-senegal",
   "metadata": {},
   "source": [
    "### 8. insert summary data first, since telemetry and degradation index off it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = api.get_fields('summary_tb', as_list=True, db=db)\n",
    "print(f\"summary_cols: {summary_cols}\")\n",
    "\n",
    "api.batch_insert(df=df[summary_cols], \n",
    "                 tb='summary_tb', \n",
    "                 db=db, \n",
    "                 cur=cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-union",
   "metadata": {},
   "source": [
    "### 9. Insert telemetry and degradation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_cols = api.get_fields('telemetry_tb', as_list=True, db=db)\n",
    "print(f\"telemetry_cols: {telemetry_cols}\")\n",
    "api.batch_insert(df=df[telemetry_cols], \n",
    "                 tb='telemetry_tb', # num_batches is optional with default value = 10\n",
    "                 db=db, \n",
    "                 cur=cur) # verbose is optional with default value = False\n",
    "\n",
    "\n",
    "degradation_cols = api.get_fields('degradation_tb', as_list=True, db=db)\n",
    "print(f\"degradation_cols: {degradation_cols}\")\n",
    "api.batch_insert(df=df[degradation_cols], \n",
    "                 tb='degradation_tb', \n",
    "                 num_batches=10,\n",
    "                 db=db, \n",
    "                 cur=cur, \n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-communist",
   "metadata": {},
   "source": [
    "## DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-disease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-causing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-scene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-spirit",
   "metadata": {},
   "source": [
    "## Misc usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "api._create_asset_type(asset_type='engine', subtype='ncmapss', description='N-CMAPSS dataset unit', db=db, cur=cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tables = api.get_tables(db)\n",
    "print(db_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_tb_cols = api.get_fields('asset_tb', as_list=True, db=db)\n",
    "asset_tb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_tb_cols = api.get_fields('engine_tb', as_list=True, db=db)\n",
    "engine_tb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "api._get_asset(serial_number='sd3kg0dk00', db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.table_exists(f\"{asset_type.type.values[0]}_{asset_type.subtype.values[0]}_tb\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type_id = api._get_asset_type(asset_type='engine', subtype='ncmapss', db=db)\n",
    "print(asset_type_id)\n",
    "print(type(asset_type_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = api._get_asset_type(type_id=1, db=db)\n",
    "print(asset_type)\n",
    "print(type(asset_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-gathering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
