{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "western-somerset",
   "metadata": {},
   "source": [
    "# Database API example for N-CMAPSS dataset\n",
    "- loads the datasets you choose,\n",
    "- creates a dataframe\n",
    "- resamples\n",
    "- saves\n",
    "#### Do this here, then use another notebook for individual tasks\n",
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuck-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import string\n",
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from time import time\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "sys.path.insert(1, base_dir)\n",
    "from package.api import DB as api\n",
    "import package.utils as utils\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-anxiety",
   "metadata": {},
   "source": [
    "## load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "rapid-cooler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-CMAPSS_DS01-005.h5\n",
      "dev\n",
      "<N-CMAPSS_DS01-005.h5> : [1. 2. 3. 4. 5. 6.]\n",
      "test\n",
      "<N-CMAPSS_DS01-005.h5> : [ 7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "h5_dir = 'data_h5'\n",
    "fnames = [\n",
    "    'N-CMAPSS_DS01-005.h5',\n",
    "    'N-CMAPSS_DS03-012.h5',\n",
    "    'N-CMAPSS_DS04.h5',\n",
    "    'N-CMAPSS_DS05.h5',\n",
    "    'N-CMAPSS_DS06.h5',\n",
    "    'N-CMAPSS_DS07.h5',\n",
    "    'N-CMAPSS_DS08a-009.h5',\n",
    "    'N-CMAPSS_DS08c-008.h5'\n",
    "]\n",
    "\n",
    "sets = ['dev', 'test']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "asset_id = 1\n",
    "\n",
    "for filename in fnames:\n",
    "    print(filename)\n",
    "    for _set in sets:\n",
    "        print(_set)\n",
    "        with h5py.File(os.path.join(base_dir, h5_dir, filename), 'r') as hdf:\n",
    "            a_data = np.array(hdf.get(f\"A_{_set}\"))\n",
    "            w_data = np.array(hdf.get(f\"W_{_set}\"))\n",
    "            x_data = np.array(hdf.get(f\"X_s_{_set}\"))\n",
    "            v_data = np.array(hdf.get(f\"X_v_{_set}\"))\n",
    "            t_data = np.array(hdf.get(f\"T_{_set}\"))\n",
    "            y_data = np.array(hdf.get(f\"Y_{_set}\"))\n",
    "\n",
    "            a_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('A_var')))]\n",
    "            w_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('W_var')))]\n",
    "            x_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('X_s_var')))]\n",
    "            v_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('X_v_var')))]\n",
    "            t_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('T_var')))]\n",
    "            \n",
    "        df_a = pd.DataFrame(data=a_data, columns=a_labels)\n",
    "        df_a['asset_id'] = -1\n",
    "        df_a['dataset'] = filename.split('_')[1].split('.')[0]\n",
    "        df_w = pd.DataFrame(data=w_data, columns=w_labels)\n",
    "        df_x = pd.DataFrame(data=x_data, columns=x_labels)\n",
    "        df_v = pd.DataFrame(data=v_data, columns=v_labels)\n",
    "        df_t = pd.DataFrame(data=t_data, columns=t_labels)\n",
    "        df_y = pd.DataFrame(data=y_data, columns=['y'])\n",
    "        print(f\"<{filename}> : {pd.unique(df_a.unit)}\")\n",
    "        for n in list(pd.unique(df_a.unit)):\n",
    "            df_a.loc[df_a['unit'] == n, 'asset_id'] = asset_id\n",
    "            asset_id = asset_id + 1\n",
    "\n",
    "        df_temp = pd.concat([df_a, df_y, df_w, df_x, df_v, df_t], axis=1)\n",
    "        #print(df_temp.head())\n",
    "        if(len(df)) == 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            df = pd.concat([df, df_temp], axis=0)      \n",
    "        \n",
    "        del df_a, df_w, df_x, df_v, df_t, df_y, a_data, w_data, t_data, x_data, y_data, df_temp\n",
    "    break\n",
    "    ####### NOTICE THE BREAK HERE!! only loading first dataset for testing purposes!!\n",
    "df = df.round(5)\n",
    "df.asset_id = df.asset_id.astype(int)\n",
    "df.unit = df.unit.astype(int)\n",
    "df.cycle = df.cycle.astype(int)\n",
    "df.hs = df.hs.astype(int)\n",
    "df.Fc = df.Fc.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-joint",
   "metadata": {},
   "source": [
    "## get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affecting-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod', 'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod', 'LPT_eff_mod', 'LPT_flow_mod']\n",
      "['alt', 'Mach', 'TRA', 'T2', 'T24', 'T30', 'T48', 'T50', 'P15', 'P2', 'P21', 'P24', 'Ps30', 'P40', 'P50', 'Nf', 'Nc', 'Wf']\n",
      "['T40', 'P30', 'P45', 'W21', 'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC', 'phi']\n"
     ]
    }
   ],
   "source": [
    "y_labels = t_labels\n",
    "t_labels = []\n",
    "t_labels.append(w_labels)\n",
    "t_labels.append(x_labels)\n",
    "t_labels = [l for labels in t_labels for l in labels]\n",
    "print(y_labels)\n",
    "print(t_labels)\n",
    "print(v_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-frontier",
   "metadata": {},
   "source": [
    "## create the augmented auxiliary data by aggregating over units\n",
    "#### NOTE the \"asset_id\" is used to assign unique numbers to the units across all datasets since the unit numbers restart in each dataset\n",
    "#### NOTE this value does not reflect the assets true ID stored in the database if there are already units in the database (but this impacts nothing, just fyi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compound-block",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>dataset</th>\n",
       "      <th>age</th>\n",
       "      <th>eol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  group_id  unit   dataset  age  eol\n",
       "0         1         1     1  DS01-005  0.0  100\n",
       "1         2         3     2  DS01-005  0.0   75\n",
       "2         3         2     3  DS01-005  0.0  100\n",
       "3         4         1     4  DS01-005  0.0   95\n",
       "4         5         3     5  DS01-005  0.0   89"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = df[['asset_id', 'Fc', 'unit', 'dataset', 'cycle']].groupby('asset_id').agg({'Fc':'max',\n",
    "                                                                         'unit':'max',\n",
    "                                                                         'dataset':'max', \n",
    "                                                                         'cycle':['min','max']})\n",
    "df_aux.reset_index(inplace=True)\n",
    "df_aux.columns=['asset_id', 'group_id', 'unit', 'dataset', 'age', 'eol']\n",
    "df_aux.age = df_aux.age - 1.0\n",
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-sampling",
   "metadata": {},
   "source": [
    "## connect to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposed-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] connecting to db.\n",
      "[INFO] connected.\n"
     ]
    }
   ],
   "source": [
    "# THESE ARE YOUR CREDENTIALS IN PLAIN TEXT!\n",
    "params = utils.get_aws_secret(\"/secret/ncmapssdb\")\n",
    "#print(params)\n",
    "db, cur =  api.connect(params)\n",
    "db.set_session(autocommit=True)\n",
    "del(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-retention",
   "metadata": {},
   "source": [
    "## create asset type\n",
    "### NOTE if the asset type already exists, the function simply returns it\n",
    "### BIG NOTE the asset_type and subtype must combine to form the table name of the component, so the table would be engine_ncmapss_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collective-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] asset_type already exists.\n",
      "   id    type  subtype                                description\n",
      "0   1  engine  ncmapss  turbine engine from N-CMAPSS dataset unit\n"
     ]
    }
   ],
   "source": [
    "asset_type = api._create_asset_type(asset_type='engine', subtype='ncmapss', description='turbine engine from N-CMAPSS dataset unit', db=db, cur=cur)\n",
    "print(asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-manchester",
   "metadata": {},
   "source": [
    "### make some serial numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_numbers = [utils.generate_serial_number(length=8) for _ in range(len(df_aux))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('serial_numbers.txt'):\n",
    "#     serial_numbers = [utils.generate_serial_number(length=8) for _ in range(len(df_aux))]\n",
    "#     with open(csv_dir + 'serial_numbers.txt', \"w\") as f:\n",
    "#         for sn in serial_numbers:\n",
    "#             f.write(f\"{sn}\\n\")\n",
    "# else:\n",
    "#     serial_numbers = []\n",
    "#     with open(\"serial_numbers.txt\", \"r\") as f:\n",
    "#         for sn in f:\n",
    "#             serial_numbers.append(sn.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-handle",
   "metadata": {},
   "source": [
    "## create assets and components\n",
    "#### this could be rewritten as a function for use with df_aux.apply()...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df_aux)):\n",
    "    asset = api._create_asset(type_id=int(asset_type.id.values[0]),\n",
    "                              common_name='ncmapss unit',\n",
    "                              age=float(df_aux.iloc[i].age),\n",
    "                              eol=float(df_aux.iloc[i].eol),\n",
    "                              rul=float(df_aux.iloc[i].eol - df_aux.iloc[i].age),\n",
    "                              units='cycles',\n",
    "                              serial_number=serial_numbers[i],\n",
    "                              db=db,\n",
    "                              cur=cur)\n",
    "    print(asset)\n",
    "\n",
    "    component = api._create_component(asset=asset, \n",
    "                                      group_id=df_aux.iloc[i].group_id, \n",
    "                                      unit=df_aux.iloc[i].unit, \n",
    "                                      dataset=df_aux.iloc[i].dataset, \n",
    "                                      db=db, \n",
    "                                      cur=cur)\n",
    "    print(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-lunch",
   "metadata": {},
   "source": [
    "### convert index to datetime \n",
    "- given there is no time information with the provided data, set the interval at your discretion (ex: 1 second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-pride",
   "metadata": {},
   "source": [
    "#### grab last record from db, and start index from that value (assuming the current dataframe does not contain any records already in the database)\n",
    "#### the \"id\" column will only start at 1 once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suited-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = api.execute(\"select max(id) from summary_tb;\", db).values[0][0]\n",
    "if type(start_id) == type(None):\n",
    "    start_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "finite-aerospace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dt</th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>Fc</th>\n",
       "      <th>hs</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>y</th>\n",
       "      <th>alt</th>\n",
       "      <th>...</th>\n",
       "      <th>fan_eff_mod</th>\n",
       "      <th>fan_flow_mod</th>\n",
       "      <th>LPC_eff_mod</th>\n",
       "      <th>LPC_flow_mod</th>\n",
       "      <th>HPC_eff_mod</th>\n",
       "      <th>HPC_flow_mod</th>\n",
       "      <th>HPT_eff_mod</th>\n",
       "      <th>HPT_flow_mod</th>\n",
       "      <th>LPT_eff_mod</th>\n",
       "      <th>LPT_flow_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>99</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1970-01-01 00:00:01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>99</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1970-01-01 00:00:02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>99</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1970-01-01 00:00:03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>99</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1970-01-01 00:00:04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>99</td>\n",
       "      <td>3043.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   dt  unit  cycle  Fc  hs  asset_id   dataset   y  \\\n",
       "0   1  1970-01-01 00:00:00     1      1   1   1         1  DS01-005  99   \n",
       "1   2  1970-01-01 00:00:01     1      1   1   1         1  DS01-005  99   \n",
       "2   3  1970-01-01 00:00:02     1      1   1   1         1  DS01-005  99   \n",
       "3   4  1970-01-01 00:00:03     1      1   1   1         1  DS01-005  99   \n",
       "4   5  1970-01-01 00:00:04     1      1   1   1         1  DS01-005  99   \n",
       "\n",
       "      alt  ...  fan_eff_mod  fan_flow_mod  LPC_eff_mod  LPC_flow_mod  \\\n",
       "0  3013.0  ...          0.0           0.0          0.0           0.0   \n",
       "1  3020.0  ...          0.0           0.0          0.0           0.0   \n",
       "2  3025.0  ...          0.0           0.0          0.0           0.0   \n",
       "3  3035.0  ...          0.0           0.0          0.0           0.0   \n",
       "4  3043.0  ...          0.0           0.0          0.0           0.0   \n",
       "\n",
       "   HPC_eff_mod  HPC_flow_mod  HPT_eff_mod  HPT_flow_mod  LPT_eff_mod  \\\n",
       "0          0.0           0.0      -0.0006           0.0          0.0   \n",
       "1          0.0           0.0      -0.0006           0.0          0.0   \n",
       "2          0.0           0.0      -0.0006           0.0          0.0   \n",
       "3          0.0           0.0      -0.0006           0.0          0.0   \n",
       "4          0.0           0.0      -0.0006           0.0          0.0   \n",
       "\n",
       "   LPT_flow_mod  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_id = 0\n",
    "df.index = pd.to_datetime(df.index, unit='s', origin='unix')\n",
    "df.index.names=['dt']\n",
    "df.reset_index(inplace=True)\n",
    "df.index += start_id + 1\n",
    "df.index.names=['id']\n",
    "df.reset_index(inplace=True)\n",
    "df.loc[:, 'dt'] = df.loc[:, 'dt'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-tamil",
   "metadata": {},
   "source": [
    "# ~~NOTE it is up to you to ensure you do not exceed your system memory when using batch insert~~\n",
    "#### handled in function now\n",
    "- the data tables are broken down slightly different then they are presented in the dataset, see the table schema\n",
    "- summary_tb: id (auto generated), asset_id, cycle, alt, Mach, TRA, T2)\n",
    "- telemetry_tb: dt (timestamp or datetime), all of the telemetry columns\n",
    "- degradation_tb: dt (timestamp or datetime), all of the degradation columns and health state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-polls",
   "metadata": {},
   "source": [
    "## insert summary data first, since telemetry and degradation index off it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = api.get_fields('summary_tb', as_list=True, db=db)\n",
    "print(f\"summary_cols: {summary_cols}\")\n",
    "api.batch_insert(df=df[summary_cols], \n",
    "                 tb='summary_tb', \n",
    "                 db=db, \n",
    "                 cur=cur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-steel",
   "metadata": {},
   "source": [
    "## Insert telemetry and degradation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_cols = api.get_fields('telemetry_tb', as_list=True, db=db)\n",
    "print(f\"telemetry_cols: {telemetry_cols}\")\n",
    "api.batch_insert(df=df[telemetry_cols], \n",
    "                 tb='telemetry_tb', # num_batches is optional with default value = 10\n",
    "                 db=db, \n",
    "                 cur=cur) # verbose is optional with default value = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "decreased-belly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degradation_cols: ['id', 'fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod', 'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod', 'LPT_eff_mod', 'LPT_flow_mod']\n",
      "inserting batch 0 of 10...\n",
      "inserting batch 1 of 10...\n",
      "inserting batch 2 of 10...\n",
      "inserting batch 3 of 10...\n",
      "inserting batch 4 of 10...\n",
      "inserting batch 5 of 10...\n",
      "inserting batch 6 of 10...\n",
      "inserting batch 7 of 10...\n",
      "inserting batch 8 of 10...\n",
      "inserting batch 9 of 10...\n",
      "inserting batch 10 of 10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7641868"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degradation_cols = api.get_fields('degradation_tb', as_list=True, db=db)\n",
    "print(f\"degradation_cols: {degradation_cols}\")\n",
    "api.batch_insert(df=df[degradation_cols], \n",
    "                 tb='degradation_tb', \n",
    "                 num_batches=10,\n",
    "                 db=db, \n",
    "                 cur=cur, \n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-netscape",
   "metadata": {},
   "source": [
    "# Putting it all together...\n",
    "## TIM HERE TODO: create function in utils that does this for the entire dataset\n",
    "In this notebook, I put a break statement after the first h5 file was processed to limit memory usage during development. The entire dataset as a dataframe uses about 40bg. These steps should be called after each dataset is loaded, or the num_batches parameter should be increased to 50 or 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-mountain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-coverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-cabin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-soccer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-pulse",
   "metadata": {},
   "source": [
    "## Misc usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "api._create_asset_type(asset_type='engine', subtype='ncmapss', description='N-CMAPSS dataset unit', db=db, cur=cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tables = api.get_tables(db)\n",
    "print(db_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_tb_cols = api.get_fields('asset_tb', as_list=True, db=db)\n",
    "asset_tb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_tb_cols = api.get_fields('engine_tb', as_list=True, db=db)\n",
    "engine_tb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "api._get_asset(serial_number='sd3kg0dk00', db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.table_exists(f\"{asset_type.type.values[0]}_{asset_type.subtype.values[0]}_tb\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type_id = api._get_asset_type(asset_type='engine', subtype='ncmapss', db=db)\n",
    "print(asset_type_id)\n",
    "print(type(asset_type_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = api._get_asset_type(type_id=1, db=db)\n",
    "print(asset_type)\n",
    "print(type(asset_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
