{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinguished-performance",
   "metadata": {},
   "source": [
    "# PREPROCESSING FILE\n",
    "- loads the datasets you choose,\n",
    "- creates a dataframe\n",
    "- resamples\n",
    "- saves\n",
    "#### Do this here, then use another notebook for individual tasks\n",
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "broken-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "sys.path.insert(1, base_dir)\n",
    "from package.api import DB as api\n",
    "import package.utils as utils\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-quantity",
   "metadata": {},
   "source": [
    "# load all data for DS08\n",
    "- two files, dev and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspended-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-CMAPSS_DS01-005.h5\n",
      "dev\n",
      "<N-CMAPSS_DS01-005.h5> : [1. 2. 3. 4. 5. 6.]\n",
      "test\n",
      "<N-CMAPSS_DS01-005.h5> : [ 7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "h5_dir = 'data_h5'\n",
    "fnames = [\n",
    "    'N-CMAPSS_DS01-005.h5',\n",
    "    'N-CMAPSS_DS03-012.h5',\n",
    "    'N-CMAPSS_DS04.h5',\n",
    "    'N-CMAPSS_DS05.h5',\n",
    "    'N-CMAPSS_DS06.h5',\n",
    "    'N-CMAPSS_DS07.h5',\n",
    "    'N-CMAPSS_DS08a-009.h5',\n",
    "    'N-CMAPSS_DS08c-008.h5'\n",
    "]\n",
    "\n",
    "sets = ['dev', 'test']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "ui = 0\n",
    "\n",
    "for filename in fnames:\n",
    "    print(filename)\n",
    "    for _set in sets:\n",
    "        print(_set)\n",
    "        with h5py.File(os.path.join(base_dir, h5_dir, filename), 'r') as hdf:\n",
    "            a_data = np.array(hdf.get(f\"A_{_set}\"))\n",
    "            w_data = np.array(hdf.get(f\"W_{_set}\"))\n",
    "            x_data = np.array(hdf.get(f\"X_s_{_set}\"))\n",
    "            xv_data = np.array(hdf.get(f\"X_v_{_set}\"))\n",
    "            t_data = np.array(hdf.get(f\"T_{_set}\"))\n",
    "            y_data = np.array(hdf.get(f\"Y_{_set}\"))\n",
    "\n",
    "            a_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('A_var')))]\n",
    "            w_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('W_var')))]\n",
    "            x_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('X_s_var')))]\n",
    "            xv_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('X_v_var')))]\n",
    "            t_labels = [l.decode('utf-8') for l in list(np.array(hdf.get('T_var')))]\n",
    "            \n",
    "        df_a = pd.DataFrame(data=a_data, columns=a_labels)\n",
    "        df_a['ui'] = -1\n",
    "        df_a['dataset'] = filename.split('_')[1].split('.')[0]\n",
    "        df_w = pd.DataFrame(data=w_data, columns=w_labels)\n",
    "        df_x = pd.DataFrame(data=x_data, columns=x_labels)\n",
    "        df_xv = pd.DataFrame(data=xv_data, columns=xv_labels)\n",
    "        df_t = pd.DataFrame(data=t_data, columns=t_labels)\n",
    "        df_y = pd.DataFrame(data=y_data, columns=['y'])\n",
    "        print(f\"<{filename}> : {pd.unique(df_a.unit)}\")\n",
    "        for n in list(pd.unique(df_a.unit)):\n",
    "            df_a.loc[df_a['unit'] == n, 'ui'] = ui\n",
    "            ui = ui + 1\n",
    "\n",
    "        df_temp = pd.concat([df_a, df_y, df_w, df_x, df_xv, df_t], axis=1)\n",
    "        #print(df_temp.head())\n",
    "        if(len(df)) == 0:\n",
    "            df = df_temp\n",
    "        else:\n",
    "            df = pd.concat([df, df_temp], axis=0)      \n",
    "        \n",
    "        del df_a, df_w, df_x, df_xv, df_t, df_y, a_data, w_data, t_data, x_data, y_data, df_temp\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-kelly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-directory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "associate-quick",
   "metadata": {},
   "source": [
    "### get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "british-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod', 'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod', 'LPT_eff_mod', 'LPT_flow_mod']\n",
      "['alt', 'Mach', 'TRA', 'T2', 'T24', 'T30', 'T48', 'T50', 'P15', 'P2', 'P21', 'P24', 'Ps30', 'P40', 'P50', 'Nf', 'Nc', 'Wf']\n",
      "['T40', 'P30', 'P45', 'W21', 'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC', 'phi']\n"
     ]
    }
   ],
   "source": [
    "y_labels = t_labels\n",
    "t_labels = []\n",
    "t_labels.append(w_labels)\n",
    "t_labels.append(x_labels)\n",
    "t_labels = [l for labels in t_labels for l in labels]\n",
    "print(y_labels)\n",
    "print(t_labels)\n",
    "print(xv_labels)\n",
    "\n",
    "csv_dir = 'data_csv'\n",
    "\n",
    "with open(os.path.join(base_dir, csv_dir, 'v_labels.txt'), \"w\") as f:\n",
    "    for l in xv_labels:\n",
    "        f.write(f\"{l}\\n\")\n",
    "        \n",
    "with open(os.path.join(base_dir, csv_dir, 'y_labels.txt'), \"w\") as f:\n",
    "    for l in y_labels:\n",
    "        f.write(f\"{l}\\n\")\n",
    "\n",
    "with open(os.path.join(base_dir, csv_dir, 't_labels.txt'), \"w\") as f:\n",
    "    for l in t_labels:\n",
    "        f.write(f\"{l}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-adoption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-standing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "professional-storm",
   "metadata": {},
   "source": [
    "## Create the augmented auxiliary data by aggregating over units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "static-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ui</th>\n",
       "      <th>Fc</th>\n",
       "      <th>unit</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>DS01-005</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ui   Fc  unit   dataset  cycle\n",
       "0   0  1.0   1.0  DS01-005  100.0\n",
       "1   1  3.0   2.0  DS01-005   75.0\n",
       "2   2  2.0   3.0  DS01-005  100.0\n",
       "3   3  1.0   4.0  DS01-005   95.0\n",
       "4   4  3.0   5.0  DS01-005   89.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max = df[['ui', 'Fc', 'unit', 'dataset', 'cycle']].groupby('ui').agg('max')\n",
    "df_max.reset_index(inplace=True)\n",
    "df_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "capital-deputy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "deadly-template",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api._create_asset_type(asset_type='engine', subtype='turbine', description='N-CMAPSS dataset unit', db=db, cur=cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "negative-point",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['owner',\n",
       " 'type_id',\n",
       " 'process_id',\n",
       " 'serial_number',\n",
       " 'common_name',\n",
       " 'age',\n",
       " 'eol',\n",
       " 'rul',\n",
       " 'units']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_tb_cols = api.get_fields('asset_tb', as_list=True, db=db)\n",
    "asset_tb_cols.remove('id')\n",
    "asset_tb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "artistic-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'group_id', 'unit', 'dataset']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_tb_cols = api.get_fields('engine_tb', as_list=True, db=db)\n",
    "engine_tb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "polar-sharing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-kuwait",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "advised-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] connecting to db.\n",
      "[INFO] connected.\n"
     ]
    }
   ],
   "source": [
    "# THESE ARE YOUR CREDENTIALS IN PLAIN TEXT!\n",
    "params = utils.get_aws_secret(\"/secret/ncmapssdb\")\n",
    "#print(params)\n",
    "db, cur =  api.connect(params)\n",
    "db.set_session(autocommit=True)\n",
    "del(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caring-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        table_name\n",
      "0  process_type_tb\n",
      "1       process_tb\n",
      "2    asset_type_tb\n",
      "3         asset_tb\n",
      "4        engine_tb\n",
      "5         group_tb\n",
      "6       summary_tb\n",
      "7     telemetry_tb\n",
      "8   degradation_tb\n",
      "9          test_tb\n"
     ]
    }
   ],
   "source": [
    "db_tables = api.get_tables(db)\n",
    "print(db_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "active-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "asset_type_id = api._get_asset_type(asset_type='engine', subtype='turbine', db=db)\n",
    "print(asset_type_id)\n",
    "print(type(asset_type_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "unknown-embassy",
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueViolation",
     "evalue": "duplicate key value violates unique constraint \"asset_tb_serial_number_key\"\nDETAIL:  Key (serial_number)=(sd3kg0dk00) already exists.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-40ccc197dafa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                   \u001b[0mserial_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sd3kg0dk00'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                   \u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                   cur=cur)\n\u001b[0m",
      "\u001b[1;32mG:\\Dropbox\\NASA\\phm2021_data_challenge\\package\\api.py\u001b[0m in \u001b[0;36m_create_asset\u001b[1;34m(type_id, owner, process_id, serial_number, common_name, age, eol, rul, units, db, cur, sandbox)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"asset_tb_serial_number_key\"\nDETAIL:  Key (serial_number)=(sd3kg0dk00) already exists.\n"
     ]
    }
   ],
   "source": [
    "api._create_asset(type_id=asset_type_id,\n",
    "                  common_name='ncmapss unit',\n",
    "                  age=0,\n",
    "                  eol=100,\n",
    "                  rul=100,\n",
    "                  units='cycles',\n",
    "                  serial_number='sd3kg0dk00',\n",
    "                  db=db,\n",
    "                  cur=cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "arabic-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "swiss-legend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.batch_insert(db, tb, cols, values, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "pressing-assist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "asset_type_id = api._create_asset_type(asset_type='engine', subtype='turbine', description='N-CMAPSS dataset unit', db=db, cur=cur)\n",
    "print(asset_type_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-reporter",
   "metadata": {},
   "source": [
    "# DO ONCE, then proceed below\n",
    "## LOAD the dataset and resample it, then SAVE it\n",
    "- for some reason I could not stop getting duplicate index errors when trying to resample before saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "df = pd.read_csv(csv_dir+'df08_all.csv')\n",
    "df.drop(columns=[df.columns[0]], inplace=True)\n",
    "df.index = pd.to_timedelta(df.index, unit='s')\n",
    "df = df.resample('10S').interpolate(method='time')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-trance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
